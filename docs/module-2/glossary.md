---
sidebar_position: 4
---

# Glossary: Digital Twin Simulation Terms

This glossary defines key terms used throughout Module 2: The Digital Twin (Gazebo & Unity).

## A

**Accelerometer**: A sensor that measures linear acceleration in three axes. Used in IMUs to determine orientation relative to gravity and measure movement.

**API (Application Programming Interface)**: A set of rules and protocols for building and interacting with software applications, such as the interface between Unity and ROS.

## D

**Depth Sensor**: A device that measures the distance to objects in a scene, providing 2.5D information that combines color (RGB) and distance (depth) data.

**Directional Light**: In Unity, a type of lighting that simulates sunlight or other distant light sources, emitting parallel rays across the entire scene.

## F

**Field of View (FOV)**: The extent of the observable world that a LiDAR sensor can capture, measured in degrees for both horizontal and vertical coverage.

**Forward Kinematics**: The use of joint parameters to compute the position and orientation of the end-effector of a robot arm.

## G

**Gyroscope**: A sensor that measures angular velocity around three axes, providing information about rotation rates and orientation changes.

## I

**IMU (Inertial Measurement Unit)**: A device that measures and reports a robot's specific force, angular rate, and sometimes the magnetic field surrounding the robot.

**Inverse Kinematics**: The mathematical process of determining the joint parameters needed to place the end-effector of a robot arm in a particular position and orientation.

## L

**LiDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances and create 3D point cloud data of the environment.

## P

**PBR (Physically-Based Rendering)**: A shading and rendering approach that simulates how light interacts with surfaces based on physical properties for more realistic visual results.

**Point Cloud**: A set of data points in 3D space, typically generated by LiDAR sensors to represent the external surface of objects.

## R

**ROS (Robot Operating System)**: A flexible framework for writing robot software, providing a collection of tools, libraries, and conventions for robot development.

**ROS#**: A bridge that enables communication between Unity and ROS systems, allowing exchange of data and messages.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to create a more accurate and robust perception of the environment than any single sensor could provide.

**Six Degrees of Freedom (6DOF)**: The six ways an object can move in 3D space: translation along X, Y, Z axes and rotation about X, Y, Z axes (roll, pitch, yaw).

## U

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model, including kinematic and dynamic properties, visual and collision models.

**Unity**: A cross-platform game engine used for creating high-fidelity simulations and visualizations for humanoid robots.

## V

**Virtual Environment**: A digital space where humanoid robots operate with physics, rendering, and sensor simulation, used for training before real-world deployment.

## H

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, focusing on how humans and robots can effectively communicate and work together.

## T

**Transform**: In robotics and 3D graphics, a component that stores the position, rotation, and scale of an object in 3D space.